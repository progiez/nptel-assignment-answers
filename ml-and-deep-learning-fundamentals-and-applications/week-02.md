# NPTEL ML And Deep Learning Fundamentals And Applications Week 02 Assignment Answers

Are you looking for NPTEL ML And Deep Learning Fundamentals And Applications Week 02 Assignment Answers? This repository will help you find your answers and solutions for Week 02 of the ML And Deep Learning Fundamentals And Applications course. We provide detailed solutions to help you complete your assignments efficiently.

![ML Deep Learning Fundamentals Applications Week 2 Answers (July-Dec 2024)](https://miro.medium.com/v2/resize:fit:875/1*fJtxe07zzYt_XQnUlM_CdA.jpeg)

ML Deep Learning Fundamentals Applications Week 2 Answers (July-Dec 2024)

**Q1.Consider a binary classification problem with two classes, A and B with prior probability P(A)=0.6\
and P(B)=0.4 .Let X be a single binary feature that can take values 0 or 1 .Given: P(X=1|A)=0.8\
and P(X=0|B)=0.7.Determine which class the classifier will classify when X=1**\
Class A\
Class B\
Equiprobable for Class A and Class B\
Not enough information

[**_**Answer: Click here to see answer**_**](https://progiez.com/ml-deep-learning-fundamentals-applications-week-2)

**Q2. Consider the following Bayesian network, where F = having the flu and C = coughing:**

0.23\
0.03\
0.35\
None of the above.

[**_**Answer: Click here to see answer**_**](https://progiez.com/ml-deep-learning-fundamentals-applications-week-2)

**These are ML Deep Learning Fundamentals Applications Week 2 Answers**

**Q3. For the above question, Are C and F independent in the given Bayesian network?**\
Yes.\
No.\
Can’t say.\
Insufficient information.

[**_**Answer: Click here to see answer**_**](https://progiez.com/ml-deep-learning-fundamentals-applications-week-2)

**Q4. Bayes’ decision theory assumes that:**\
The feature vectors are dependent on each other.\
The feature vectors are normally distributed.\
The feature vectors are identically distributed.\
The feature vectors are uniformly distributed.

[**_**Answer: Click here to see answer**_**](https://progiez.com/ml-deep-learning-fundamentals-applications-week-2)

**These are ML Deep Learning Fundamentals Applications Week 2 Answers**

**Q5. Assume that the word ‘offer’ occurs in 80% of the spam messages in my account. Also, let’s assume ‘offer’ occurs in 10% of my desired e-mails. If 30% of the received e-mails are considered as a scam, and I will receive a new message which contains ‘offer’, what is the probability that it is spam?**\
0.778\
0.774\
0.668\
0.664

[**_**Answer: Click here to see answer**_**](https://progiez.com/ml-deep-learning-fundamentals-applications-week-2)

**Q6. The optimal decision in Bayes Decision Theory is the one that**

Minimizes the error rate.\
Maximizes the error rate.\
Minimizes the loss function.\
Maximizes the loss function.

Answer: Updating Soon (in progress)

**These are ML Deep Learning Fundamentals Applications Week 2 Answerss**

**Q7. The risk function in Bayesian decision theory combines:**\
The prior probabilities and the likelihood function.\
The decision boundaries and the feature vectors.\
The training set and the test set.\
The loss function and the decision rule

[**_**Answer: Click here to see answer**_**](https://progiez.com/ml-deep-learning-fundamentals-applications-week-2)

**Q8. The loss function used in risk-based Bayesian decision theory:**Quantifies the cost of different types of errors.\
Is equal to the likelihood function.\
Ignores the prior probabilities of the classes.\
Is not used in the decision-making process

**Answer: Updating Soon (in progress)**

**These are Machine Learning and Deep Learning Fundamentals and Applications Week 1 Nptel Assignment Answers**

**Q9. The risk-based Bayesian decision rule accounts for the consequences of different decisions by considering the:**\
Number of features in the dataset\
The complexity of the classifier\
Uncertainty in the data and the associated losses\
Mean and standard deviation of the feature vectors

**Answer: Updating Soon (in progress)**

**Q10. The generalized form of a Bayesian network that represents and solves decision problems under uncertain knowledge is known as an?**\
Directed Acyclic Graph\
Table of conditional probabilities\
Influence diagram\
None of the above

**Answer: Updating Soon (in progress)**
