# NPTEL Deep Learning IIT Ropar Week 07 Assignment Answers

Are you looking for NPTEL Deep Learning IIT Ropar Week 07 Assignment Answers? This repository will help you find your answers and solutions for Week 07 of the Deep Learning IIT Ropar course. We provide detailed solutions to help you complete your assignments efficiently.

## Deep Learning IIT Ropar Week 7 Nptel Assignment Answers (Jan-Apr 2025)

***

**Que.1** Which of the following statements about L2 regularization is true?\
a) It adds a penalty term to the loss function that is proportional to the absolute value of the weights\
b) It results in sparse solutions for w\
c) It adds a penalty term to the loss function that is proportional to the square of the weights\
d) It is equivalent to adding Gaussian noise to the weights\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.2** Consider two models:\
    f¹(x) = w₀ + w₁x\
    f²(x) = w₀ + w₁x² + w₂x² + w₄x⁴ + w₅x⁵

Which of these models has higher complexity?\
a) f¹(x)\
b) f²(x)\
c) It is not possible to decide without knowing the true distribution of data points in the dataset\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.3** We generate the data using the following model:\
    y = 7x³ + 12x + x + 2.

We fit the two models f¹(x) and f²(x) on this data and train them using a neural network.

a) f¹(x) has a higher bias than f²(x)\
b) f²(x) has a higher bias than f¹(x)\
c) f²(x) has a higher variance than f¹(x)\
d) f¹(x) has a higher variance than f²(x)\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.4** Suppose that we apply Dropout regularization to a feedforward neural network. Suppose further that the mini-batch gradient descent algorithm is used for updating the parameters of the network. Choose the correct statement(s):

a) The dropout probability _p_ can be different for each hidden layer\
b) Batch gradient descent cannot be used to update the parameters of the network\
c) Dropout with _p_ = 0.5 acts as an ensemble regularizer\
d) The weights of the neurons that were dropped during forward propagation at the _t-th_ iteration will not get updated during _t+1-th_ iteration\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

[****See also**  **Deep Learning IIT Ropar Week 2 Nptel Assignment Answers****](https://progiez.com/deep-learning-iit-ropar-week-2-nptel-assignment-answers)

***

**Que.5** We have trained four different models on the same dataset using various hyperparameters. The training and validation errors for each model are provided below. Based on this information, which model is likely to perform best on the test dataset?

a) Model 1\
b) Model 2\
c) Model 3\
d) Model 4\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.6** Consider a function _L(w,b) = 0.4w² + 7b² + 1_ and its contour plot. What is the value of _L(w_, b\*)\* where _w_\*\* and _b_\*\* are the values that minimize the function?\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.7** What is the sum of the elements of ∇L(w\*,b\*)?\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.8** What is the determinant of _H_L(w\*,b\*), where _H_ is the Hessian of the function?\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.9** Compute the Eigenvalues and Eigenvectors of the Hessian. According to the eigenvalues of the Hessian, which parameter is the loss more sensitive to?\
a) b\
b) w\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)

***

**Que.10** Consider the problem of recognizing an alphabet (uppercase or lowercase) of the English language in an image. There are 26 alphabets in the language. A team decided to use a CNN network to solve this problem. Suppose that the data augmentation technique is being used for regularization. Then which of the following transformations on all the training images is (are) appropriate?

a) Rotating the images by ±10°\
b) Rotating the images by ±180°\
c) Translating the image by 1 pixel in all directions\
d) Cropping\
[View Answer](https://my.progiez.com/courses/deep-learning-iit-ropar-nptel-answers/)
