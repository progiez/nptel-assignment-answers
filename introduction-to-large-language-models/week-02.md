# NPTEL Introduction to Large Language Models Week 02 Assignment Answers

Are you looking for NPTEL Introduction to Large Language Models Week 02 Assignment Answers? This repository will help you find your answers and solutions for Week 02 of the Introduction to Large Language Models course. We provide detailed solutions to help you complete your assignments efficiently.


## Introduction to Large Language Models Week 2 Answers (July-Dec 2025)

Course link: [Click here](https://onlinecourses.nptel.ac.in/noc25_cs161/preview)

**Question 1.** **Which of the following does not directly affect perplexity?**\
a) Vocabulary size\
b) Sentence probability\
c) Number of tokens\
d) Sentence length

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 2.** **Which equation expresses the chain rule for a 4-word sentence?**\
a) P(w1, w2, w3, w4) = P(w1) + P(w2|w1) + P(w3|w2) + P(w4|w3)\
b) P(w1, w2, w3, w4) = P(w1) × P(w2|w1) × P(w3|w1, w2) × P(w4|w1, w2, w3)\
c) P(w1, w2, w3, w4) = P(w1) × P(w2|w1) × P(w3|w2) × P(w4|w3)\
d) P(w1, w2, w3, w4) = P(w4|w3) × P(w3|w2) × P(w2|w1) × P(w1)

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 3.** **Which assumption allows n-gram models to reduce computation?**\
a) Bayes Assumption\
b) Chain Rule\
c) Independence Assumption\
d) Markov Assumption

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 4.** **In a trigram language model, which of the following is a correct example of linear interpolation?**\
a) P(wi∣wi−2,wi−1)=λ1P(wi∣wi−2,wi−1)\
b) P(wi∣wi−2,wi−1)=λ1P(wi∣wi−2,wi−1)+λ2P(wi∣wi−1)+λ3P(wi)\
c) P(wi∣wi−2,wi−1)=max(P(wi∣wi−2,wi−1),P(wi∣wi−1))\
d) P(wi∣wi−2,wi−1)=P(wi)P(wi−1)/P(wi−2)

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 5.** **A trigram model is equivalent to which order Markov model?**\
a) 3\
b) 2\
c) 1\
d) 4

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 6.** **Which smoothing technique leverages the number of unique contexts a word appears in?**\
a) Good-Turing\
b) Add-k\
c) Kneser-Ney\
d) Absolute Discounting

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 7.** **Assuming a bi-gram language model, calculate the probability of the sentence: birds fly in the blue sky. Ignore the unigram probability of P() in your calculation.**\
a) 2/37\
b) 1/27\
c) 0\
d) 1/36

[****See also**  **Organizational Behaviour Nptel Week 2 Answers****](https://progiez.com/organizational-behaviour-nptel-week-2-answers)

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

**Question 8.** **Assuming a bi-gram language model, calculate the perplexity of the sentence: birds fly in the blue sky. Please do not consider and as words of the sentence.**\
a) 271/4\
b) 271/5\
c) 91/6\
d) None of these

[**View Answers**](https://my.progiez.com/courses/introduction-to-large-language-models-nptel-answers/)

***

[Click here for all nptel assignment answers](https://progiez.com/nptel-assignment-answers)

These are Introduction to Large Language Models Week 2 Answers
